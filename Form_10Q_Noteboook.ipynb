{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Form-10Q-Noteboook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3dC28fg4/Ecx/rsReqW+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/jupyter/blob/master/Form_10Q_Noteboook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygjb5AruwuFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pandas-datareader\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "import logging\n",
        "from pandas.tseries.offsets import BDay\n",
        "import requests\n",
        "import numpy as np\n",
        "import urllib\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas.tseries.offsets import BDay\n",
        "import pandas_datareader.data as dr\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eQxHEmNw243",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!mkdir -p data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_jPbEA35SvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "def get_iexapi_keys():\n",
        "  with open('gdrive/My Drive/passwords/iexapi.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n",
        "def get_nlp_service_keys():\n",
        "  with open('gdrive/My Drive/passwords/nlp.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n",
        "def get_newsapi_keys():\n",
        "  with open('gdrive/My Drive/passwords/newsapi.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n",
        "def getfmpkeys():\n",
        "  with open('gdrive/My Drive/passwords/fmprep.keys') as f:\n",
        "    return f.readlines()[0]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn7Ls29HxM8Z",
        "colab_type": "text"
      },
      "source": [
        "<h3> Fetching 10-q datset </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjYL57a1w-3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp   gs://mm_dataflow_bucket/inputs/quarterly_earnings_mixed_tickets_dataset.csv data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elm_xsTfE_aT",
        "colab_type": "text"
      },
      "source": [
        "<h3> Filtering on BAC stock </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKNRyuc-EGcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setting_index(bac_df):\n",
        "  bac_df = bac_df.set_index('cob_date')\n",
        "  bac_df = bac_df.sort_index(ascending=True)\n",
        "  return bac_df\n",
        "\n",
        "def get_price_after_quarter(as_of_date, ticker):\n",
        "  #print('Current as of date:{}={}'.format(as_of_date, type(as_of_date)))\n",
        "  #print('ticker:{}'.format(ticker))\n",
        "  if isinstance(as_of_date, date):\n",
        "    dt = as_of_date\n",
        "  else:\n",
        "    dt = datetime.strptime(as_of_date, '%Y-%m-%d').date()\n",
        "  try:\n",
        "    price=  dr.get_data_yahoo(ticker, dt, dt)[['Close']].values.tolist()[0][0]\n",
        "    #print('rice for {} is {}'.format(as_of_date, price))\n",
        "    return price\n",
        "  except Exception as e:\n",
        "    print('Unable to find price for {} type){}, getting pre vday'.format(as_of_date, type(as_of_date)))\n",
        "    prev_day = dt + BDay(1)\n",
        "    return get_price_after_quarter(prev_day.date(), ticker)\n",
        "\n",
        "\n",
        "def find_price(bac_df, ticker, field):\n",
        "  bac_df['price'] = bac_df[field].apply(get_price_after_quarter, args=[ticker])\n",
        "  return bac_df\n",
        "\n",
        "\n",
        "def find_historical_price_iex(ticker, as_of_date):\n",
        "  base_url = 'https://cloud.iexapis.com/stable/stock/{symbol}/chart/1d/{date}?token={token}&chartByDay=true&chartCloseOnly=true'.format(symbol=ticker, date=as_of_date.strftime('%Y%m%d'),\n",
        "                                                                                          token=get_iexapi_keys())\n",
        "  print('getting from url{}'.format(base_url))\n",
        "  return requests.get(base_url).json()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h--BubQj0bkw",
        "colab_type": "text"
      },
      "source": [
        "<h3> Using FinancialModellingPrep. We can still get 250 request per day for free..</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg_8AyDXvtCD",
        "colab_type": "text"
      },
      "source": [
        "<h3>First retrieving  all ticker and indicators </h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RM9cDPjhvr9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_tickers():\n",
        "  !gsutil cp gs://datascience-bucket-mm/all_sectors.csv  data\n",
        "  df = pd.read_csv('data/all_sectors.csv')\n",
        "  renamed = df.rename({'Unnamed: 0' : 'ticker'}, axis=1)\n",
        "\n",
        "  # grouping by ticker\n",
        "  print(renamed.groupby(['Sector']).count())\n",
        "  return renamed\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_7Wh-TR107V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://medium.com/swlh/teaching-a-machine-to-trade-stocks-like-warren-buffett-part-i-445849b208c6\n",
        "def get_10q_statements(ticker):\n",
        "  try:\n",
        "    print('Getting tickers for {}'.format(ticker))\n",
        "    base_url = 'https://financialmodelingprep.com/api/v3/key-metrics/{}?period=quarter&apikey=79d4f398184fb636fa32ac1f95ed67e6'.format(ticker.upper())\n",
        "    print('Opening:{}'.format(base_url))\n",
        "    res = requests.get(base_url).json()\n",
        "    print('Respone has:{}'.format(len(res)))\n",
        "    return pd.DataFrame(res).head(12)\n",
        "  except Exception as e:\n",
        "    print('Exception for {}:{}'.format(ticker, str(e)))\n",
        "\n",
        "def get_10q_statement_iex(ticker, num_statements):\n",
        "  base_url = 'https://cloud.iexapis.com/stable/time-series/REPORTED_FINANCIALS/{symbol}/10-Q?last={numstats}&token={token}'.format(symbol=ticker, \n",
        "                                                                                          numstats=num_statements,\n",
        "                                                                                          token=get_iexapi_keys())\n",
        "  print('Executing:{}'.format(base_url))\n",
        "  data =  requests.get(base_url).json()\n",
        "  return pd.DataFrame(data)\n",
        "  \n",
        "\n",
        "def get_tickers_for_sector(sector_name):\n",
        "  print('Getting all tickers for {}'.format(sector_name))\n",
        "  all_tickers = get_all_tickers()\n",
        "  print('shape is:{}'.format(all_tickers.shape))\n",
        "  sector_ticks = all_tickers[all_tickers['Sector'] == sector_name]\n",
        "  return sector_ticks['ticker'].values.tolist()\n",
        "\n",
        "\n",
        "def _create_10q_data_for_ticker(ticker):\n",
        "  print('Fetching financial data....')\n",
        "  find_df = get_10q_statements(ticker)\n",
        "  if find_df is not None:\n",
        "    with_price = find_price(find_df, ticker, 'date')\n",
        "    return with_price\n",
        "\n",
        "\n",
        "#stmnts = [get_10q_statements(t) for t in ['GE', 'WP']]\n",
        "#all_dt = pd.concat(stmnts)\n",
        "#print(all_dt.shape)\n",
        "get_all_tickers()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irkRrUFn_7s1",
        "colab_type": "text"
      },
      "source": [
        "<h3> Testing 10q statements on Amazon </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhOhtL119Ign",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Good enough for training, but not for latest. We'll see what we got from financialmodellingprep. Mayb we  shold spend July checking\n",
        "def build_dataframe_for_ticker(ticker):\n",
        "  try:\n",
        "    res = get_10q_statements(ticker).dropna(axis=1)\n",
        "    res['cob_date'] = res['date'].apply(lambda ds: datetime.strptime(ds, '%Y-%m-%d')).head(1)\n",
        "    res = find_price(res, 'amzn', 'date')\n",
        "    return res\n",
        "  except Exception as  e:\n",
        "    print('Cannot find statements for {}'.format(ticker))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoqTEIDbFAfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "build_dataframe_for_ticker('AMZN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D90R7YgFzjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ticker_and_sectors = get_all_tickers()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3ZJJaPHPdhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tickers_for_sector(sector_name):\n",
        "  print('Getting ticker for :{}'.format(sector_name))\n",
        "  utilities_tickers = ticker_and_sectors[ticker_and_sectors['Sector'] == sector_name]\n",
        "  return set(utilities_tickers.ticker.values.tolist()) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yAQKc1WPZ72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comm_svc = get_tickers_for_sector('Communication Services')\n",
        "print('finding data for {}'.format(len(comm_svc)))\n",
        "ut_dframes = dict((t, build_dataframe_for_ticker(t) ) for t in comm_svc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYx1e1ZrFGay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remember to filter out cob dates earlier than 2015\n",
        "all_data = pd.concat([d for d in ut_dframes.values() if d is not None], axis=0)\n",
        "print(all_data.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkFFPPAxOlxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data.to_csv('all_data_utilities_df_1008.csv')\n",
        "!gsutil cp  all_data_utilities_df_1008.csv gs://mm_dataflow_bucket/inputs/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD9sZFdEGgQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data.columns\n",
        "all_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH1DTwutADqT",
        "colab_type": "text"
      },
      "source": [
        "<h3> Now we shold find only relevant indicators. we have over 90 of them </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqi7l_puCwKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper functions\n",
        "def setting_index(df):\n",
        "    \"\"\"\n",
        "    Returns a sorted datetime index\n",
        "    \"\"\"\n",
        "    df['Quarter end'] = pd.to_datetime(df['date'])\n",
        "    df.set_index(\"Quarter end\", inplace=True)\n",
        "    return df.sort_index(ascending=True)\n",
        "  \n",
        "def class_creation(df, thres=3):\n",
        "    \"\"\"\n",
        "    Creates classes of:\n",
        "    - buy(1)\n",
        "    - hold(2)\n",
        "    - sell(0)\n",
        "    \n",
        "    Threshold can be changed to fit whatever price percentage change is desired\n",
        "    \"\"\"\n",
        "    if df['price'] >= thres :\n",
        "        # Buys\n",
        "        return 1\n",
        "    \n",
        "    elif df['price'] <= -thres :\n",
        "        # Sells\n",
        "        return 0\n",
        "    \n",
        "    else:\n",
        "        # Holds\n",
        "        return 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxLY9yvZC6Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(stocks_df):\n",
        "  for i in stocks_df.keys():\n",
        "    print('Setting index..')\n",
        "    stocks_df[i] = setting_index(stocks_df[i])\n",
        "    \n",
        "  # Replacing all \"None\" values with NaN\n",
        "  for i in stocks_df.keys():\n",
        "    print('Replacing noex.. for {}'.format(i))\n",
        "    stocks_df[i].replace(\"None\", 0, inplace=True)\n",
        "      \n",
        "  # Creating a new dictionary that contains the numerical values, then converting all values to numeric values\n",
        "  num_df = {}\n",
        "  print(' numeric..')\n",
        "  for i in stocks_df.keys():\n",
        "      num_df[i] = stocks_df[i].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "      \n",
        "  # Replacing values with percent difference or change\n",
        "  pcnt_df = {}\n",
        "  for i in num_df.keys():\n",
        "      pcnt_df[i] = num_df[i].pct_change(periods=1).apply(lambda x: x*100)\n",
        "      \n",
        "  # Replacing infinite values with NaN\n",
        "  for i in pcnt_df.keys():\n",
        "      print('Replacing infinte')\n",
        "  \n",
        "      pcnt_df[i] = pcnt_df[i].replace([np.inf, -np.inf], np.nan)\n",
        "      \n",
        "  # Creating a new DataFrame that contains the class 'Decision' determining if a quarterly reports improvement is a buy, hold, or sell.\n",
        "  new_df = {}\n",
        "  for i in pcnt_df.keys():\n",
        "      print('Creating decision ')\n",
        "  \n",
        "      # Assigning the new DF\n",
        "      new_df[i] = pcnt_df[i]\n",
        "      \n",
        "      # Creating the new column with the classes, shifted by -1 in order to know if the prices will increase/decrease in the next quarter.\n",
        "      new_df[i]['Decision'] = new_df[i].apply(class_creation, axis=1).shift(-1)\n",
        "      \n",
        "  # Excluding the first and last rows\n",
        "  for i in new_df.keys():\n",
        "      new_df[i] = new_df[i][1:-1]\n",
        "  return new_df\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZNL0cdwWhYZ",
        "colab_type": "text"
      },
      "source": [
        "<h3>Build dictionary of tickers </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t01ofwIWkoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ticks =  all_data.symbol.values.tolist()\n",
        "all_dict = dict((tick, all_data[all_data['symbol'] == tick]) for tick in ticks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAErI-YBIexv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_data.columns\n",
        "updated = prepare_data(all_dict)\n",
        "type(updated)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9e0nu4hJ3j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df = pd.concat([v for v in updated.values()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4AlLpK_KW3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df.to_csv('all_data_utilities_df_1008_prepared.csv')\n",
        "!gsutil cp  all_data_utilities_df_1008_prepared.csv gs://mm_dataflow_bucket/inputs/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVEZRlfva1l2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://mm_dataflow_bucket/inputs/all_data_utilities_df_1008_prepared.csv ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eVAcFsybBDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df = pd.read_csv('all_data_utilities_df_1008_prepared.csv')\n",
        "final_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0pFj-Lf-Dn3",
        "colab_type": "text"
      },
      "source": [
        "<h3> Visualizing data </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72EV0m695Ha0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import _pickle as pickle\n",
        "\n",
        "# Separating each class into respective DataFrames\n",
        "buy_df = final_df[final_df['Decision']==1].loc[:, final_df.columns != 'Decision'].reset_index(drop=True)\n",
        "hold_df = final_df[final_df['Decision']==2].loc[:, final_df.columns != 'Decision'].reset_index(drop=True)\n",
        "sell_df = final_df[final_df['Decision']==0].loc[:, final_df.columns != 'Decision'].reset_index(drop=True)\n",
        "\n",
        "# Visualizing in matplotlib\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "# Plotting the count of each DataFrame of each class\n",
        "plt.bar(\"Buy\", buy_df.shape[0])\n",
        "plt.bar(\"Sell\", sell_df.shape[0])\n",
        "plt.bar(\"Hold\", hold_df.shape[0])\n",
        "\n",
        "plt.ylabel(\"# of Quarterly Reports\")\n",
        "plt.title('Count of Quarterly Reports')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEA437JW_ftt",
        "colab_type": "text"
      },
      "source": [
        "<h3> Finding correlation in our data </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Bu81rr-Mp5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CorrMtx(df, dropDuplicates = True):\n",
        "    \"\"\"\n",
        "    Takes in a Correlation DF and excludes nonessential visuals.\n",
        "    Creates a more visually pleasing correlation matrix\n",
        "    \"\"\"\n",
        "\n",
        "    # Exclude duplicate correlations by masking uper right values\n",
        "    if dropDuplicates:    \n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "    # Set background color / chart style\n",
        "    sns.set_style(style = 'white')\n",
        "\n",
        "    # Set up  matplotlib figure\n",
        "    f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "    # Add diverging colormap from red to blue\n",
        "    cmap = sns.diverging_palette(250, 10, as_cmap=True)\n",
        "\n",
        "    # Draw correlation plot with or without duplicates\n",
        "    if dropDuplicates:\n",
        "        sns.heatmap(df, mask=mask, cmap=cmap, \n",
        "                square=True,\n",
        "                linewidth=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
        "    else:\n",
        "        sns.heatmap(df, cmap=cmap, \n",
        "                square=True,\n",
        "                linewidth=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
        "        \n",
        "        \n",
        "# Correlation DF of all classes\n",
        "corr = final_df.corr().iloc[[-1],:-1]\n",
        "\n",
        "# Plotting the Correlation DF as a heatmap\n",
        "plt.figure(figsize=(14,1))\n",
        "sns.heatmap(corr, annot=False, linewidths=.1, cmap=\"coolwarm\")\n",
        "plt.xticks()\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMnoBECd_wXW",
        "colab_type": "text"
      },
      "source": [
        "<h2>Feature Selection </h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-qYIFxP_3M8",
        "colab_type": "text"
      },
      "source": [
        "<h4>Finding top 10 features </h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNsTwbyT_mOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_top_10(input_df):\n",
        "  corr = input_df.corr().iloc[[-1],:-1]\n",
        "\n",
        "  # Sorting our Correlation DF by their absolute values and selecting the top 10\n",
        "  top10_corr = corr.transpose().apply(abs).sort_values(by='Decision', ascending=False)[:10]\n",
        "\n",
        "  # Creating a new DF with the features from the top10_corr and joing the 'Decision' class labels\n",
        "  top10_corr_df = input_df[top10_corr.index].join(final_df.Decision)\n",
        "\n",
        "  # Pickling the DF for use in our Classification models\n",
        "  with open(\"data/top10_corr_df_1008.pkl\", \"wb\") as fp:\n",
        "    pickle.dump(top10_corr_df, fp)\n",
        "  !gsutil cp  data/top10_corr_df_1008.pkl gs://mm_dataflow_bucket/inputs/\n",
        "\n",
        "  return top10_corr_df\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRVoDOPkAqgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top10 = find_top_10(final_df)\n",
        "top10.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9YKL07JBLcn",
        "colab_type": "text"
      },
      "source": [
        "<h4> Method 2. Using a Random Classifier </h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGTvKG7UAvJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the necessary libraries\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "def find_top_10_via_classifier(input_df):\n",
        "  # Instatiating the classifier\n",
        "  forest = ExtraTreesClassifier(n_estimators=200)\n",
        "\n",
        "  # Setting the corresponding variables for our classifier\n",
        "  X = input_df.drop(['Decision'], 1)\n",
        "  y = input_df.Decision\n",
        "\n",
        "  # Fitting the classifier\n",
        "  print('Fitting')\n",
        "  forest.fit(X, y)\n",
        "\n",
        "  # Determining the important features\n",
        "  importances = forest.feature_importances_\n",
        "  print('finding std')\n",
        "  # The standard deviation among the trees for the important features\n",
        "  std = np.std([i.feature_importances_ for i in forest.estimators_], axis=0)\n",
        "\n",
        "  # Indexing and sorting the important features\n",
        "  indices = np.argsort(importances)[::-1]\n",
        "\n",
        "  # Assigning the top 10 features as a new DF\n",
        "  top10_df = input_df[X.columns[indices][:10]].join(final_df.Decision)\n",
        "\n",
        "  # Exporting the top 10 features DF\n",
        "  with open(\"top10_df_classifier_1008.pkl\", \"wb\") as fp:\n",
        "      pickle.dump(top10_df, fp)\n",
        "  return X, indices, importances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdPhIur3BdPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned = final_df.drop(columns=['Quarter end', 'date', 'cob_date']).fillna(0.0)\n",
        "#print(cleaned.columns)\n",
        "#print(cleaned.head(2).T)\n",
        "#X.columns\n",
        "#!gsutil cp  top10_df_classifier.pkl gs://mm_dataflow_bucket/inputs/\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BEeBdtRdY2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_idx = cleaned.reset_index()\n",
        "X, indices, importances= find_top_10_via_classifier(no_idx)\n",
        "!gsutil cp  top10_df_classifier_1008.pkl gs://mm_dataflow_bucket/inputs/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VZD3Yo7E9Yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://mm_dataflow_bucket/inputs/top10_df_classifier.pkl ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0gzLOH1FGoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle('top10_df_classifier.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slCE1ADGFUrd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df.shape)\n",
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxJWfHJDBt2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualizing features\n",
        "# Matplotlib style to use\n",
        "plt.style.use('seaborn')\n",
        "\n",
        "# Printing out the different features as a list\n",
        "print(\"Feature Rankings:\")\n",
        "\n",
        "# Showing the top 10 features\n",
        "for i in range(10):\n",
        "    print(f\"{i+1}. {X.columns[indices[i]]}: {importances[indices[i]]}\")\n",
        "    \n",
        "# Plotting the top 10 features\n",
        "plt.figure(figsize=(14,7))\n",
        "\n",
        "plt.title(\"Feature Importances for the Original Dataset\")\n",
        "plt.bar(range(X.shape[1]), importances[indices], yerr=std[indices], align='center')\n",
        "\n",
        "plt.xticks(range(X.shape[1]), X.columns[indices], rotation=90)\n",
        "plt.xlim([-1, 11.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxVLMSOJCfgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}