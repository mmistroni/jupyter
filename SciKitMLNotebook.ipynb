{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://mm_dataflow_bucket/inputs/technical_indicators_dataset.csv data\n",
    "    \n",
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Useful function </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from google.cloud import storage\n",
    "from googleapiclient.discovery import build\n",
    "from apiclient.http import MediaIoBaseDownload\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Useful Functions </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_bucket(filename, bucket_name):\n",
    "  gcs_service = build('storage', 'v1')\n",
    "  # The name for the new bucket\n",
    "  holder = 'data/{}'.format(filename.split('/')[-1])\n",
    "  print('Reading {} from {}'.format(filename,bucket_name))\n",
    "  with open(holder, 'wb') as f:\n",
    "    request = gcs_service.objects().get_media(bucket=bucket_name,\n",
    "                                              object=filename)\n",
    "    media = MediaIoBaseDownload(f, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "      # _ is a placeholder for a progress object that we ignore.\n",
    "      # (Our file is small, so we skip reporting progress.)\n",
    "      _, done = media.next_chunk()\n",
    "\n",
    "  print('Download complete')\n",
    "  return pd.read_csv(holder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "  \n",
    "def get_price_var(symbol):\n",
    "    '''\n",
    "    Get historical price data for a given symbol leveraging the power of pandas_datareader and Yahoo.\n",
    "    Compute the difference between first and last available time-steps in terms of Adjusted Close price..\n",
    "    Input: ticker symbol\n",
    "    Output: price variation \n",
    "    '''\n",
    "    # read data\n",
    "    prices = dr.get_data_yahoo(symbol, '2019-01-01', '2020-03-01')['Adj Close']\n",
    "\n",
    "    # get all timestamps for specific lookups\n",
    "    today = prices.index[-1]\n",
    "    start = prices.index[0]\n",
    "\n",
    "    # calculate percentage price variation\n",
    "    price_var = ((prices[today] - prices[start]) / prices[start]) * 100\n",
    "    return price_var\n",
    "\n",
    "def read_from_bucket(filename, bucket_name):\n",
    "  gcs_service = build('storage', 'v1')\n",
    "  # The name for the new bucket\n",
    "  holder = 'data/{}'.format(filename.split('/')[-1])\n",
    "  print('Reading {} from {}'.format(filename,bucket_name))\n",
    "  with open(holder, 'wb') as f:\n",
    "    request = gcs_service.objects().get_media(bucket=bucket_name,\n",
    "                                              object=filename)\n",
    "    media = MediaIoBaseDownload(f, request)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "      # _ is a placeholder for a progress object that we ignore.\n",
    "      # (Our file is small, so we skip reporting progress.)\n",
    "      _, done = media.next_chunk()\n",
    "\n",
    "  print('Download complete')\n",
    "  return pd.read_csv(holder)\n",
    "\n",
    "def get_latest_price_yahoo(symbol, as_of_date=date.today()):\n",
    "  try:#\n",
    "    print('--latest price for{}'.format(symbol))\n",
    "    res = dr.get_data_yahoo(symbol, as_of_date, as_of_date)[['Close']]\n",
    "    res['Symbol'] = symbol\n",
    "    return res.tail(1)\n",
    "  except Exception as e :\n",
    "\n",
    "    return pd.DataFrame(columns=[symbol])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scaling data </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (1.1.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Machine learning (preprocessing, models, evaluation)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "def create_train_and_test_split(dataset, label):\n",
    "  print('Creating Train and Test Split where label is :{}'.format(label))\n",
    "  train_split, test_split = train_test_split(dataset, test_size=0.2, random_state=1, stratify=dataset[label])\n",
    "  X_train = train_split.drop([label], axis=1).values\n",
    "  y_train = train_split[label].values\n",
    "  X_test = test_split.drop([label], axis=1).values\n",
    "  y_test = test_split[label].values\n",
    "  print()\n",
    "  print(f'Number of training samples: {X_train.shape[0]}')\n",
    "  print()\n",
    "  print(f'Number of testing samples: {X_test.shape[0]}')\n",
    "  print()\n",
    "  print(f'Number of features: {X_train.shape[1]}')\n",
    "  return X_train, y_train, X_test, y_test, test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def create_algo(classifier):\n",
    "  steps = [('scaler', StandardScaler()), \n",
    "           #('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n",
    "           ('algo', classifier)]\n",
    "  pipeline = Pipeline(steps) # define the pipeline object.\n",
    "  return pipeline\n",
    "\n",
    "\n",
    "def create_gridsearch(classifier, tuned_parameters, randomized=False):\n",
    "  print('Creating Gridsearch for {}'.format(classifier))\n",
    "  ppln = create_algo(classifier)\n",
    "\n",
    "  input_params = tuned_parameters if isinstance(tuned_parameters, dict) else tuned_parameters[0]\n",
    "  new_params = dict(('algo__{}'.format(k), v) for k,v in input_params.items())\n",
    "  if randomized:\n",
    "    print('Creating randomized/')\n",
    "    return RandomizedSearchCV(ppln,\n",
    "                      [new_params],\n",
    "                      n_jobs=4,\n",
    "                      scoring='precision_weighted',\n",
    "                      cv=3)\n",
    "  return GridSearchCV(ppln,\n",
    "                      [new_params],\n",
    "                      n_jobs=4,\n",
    "                      scoring='precision_weighted',\n",
    "                      cv=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Testing Various Algorithms </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_SVM2(x, y, randomized):\n",
    "  print('Running SVM')\n",
    "  from sklearn.svm import SVC\n",
    "  \n",
    "  tuned_parameters = [{'kernel': ['rbf', 'linear', 'poly'],\n",
    "                      'gamma': [1e-3, 1e-4],\n",
    "                     'C': [0.01, 0.1, 1, 10, 100]}]\n",
    "  print('finding best grid search')\n",
    "  clf1 = create_gridsearch(SVC(random_state=1),tuned_parameters, randomized)\n",
    "  clf1.fit(x, y)\n",
    "  \n",
    "  \n",
    "  bs,bp = clf1.best_score_, clf1.best_params_\n",
    "  \n",
    "  #print('Best score and parameters found on development set:')\n",
    "  #print()\n",
    "  #print('%0.3f for %r' % (bs, bp))\n",
    "  #print()\n",
    "  return bs, bp, clf1\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def run_with_random_forest(x, y):\n",
    "  # Parameter grid to be tuned\n",
    "  tuned_parameters = {'n_estimators': [32, 256],\n",
    "                      'max_features': ['auto', 'sqrt'],\n",
    "                      'max_depth': [4, 5, 6],\n",
    "                      'criterion': ['gini', 'entropy']}\n",
    "  clf2 = create_gridsearch(RandomForestClassifier(random_state=1),\n",
    "                      tuned_parameters)\n",
    "  clf2.fit(x, y)\n",
    "  \n",
    "  bs,bp = clf2.best_score_, clf2.best_params_\n",
    "  \n",
    "  #print('Best score and parameters found on development set:')\n",
    "  #print()\n",
    "  #print('%0.3f for %r' % (bs, bp))\n",
    "  #print()\n",
    "  return bs, bp, clf2\n",
    "  \n",
    "  \n",
    "def run_with_XGBClassifer(x, y):\n",
    "  # Parameter grid to be tuned\n",
    "  tuned_parameters = {'learning_rate': [0.01, 0.001],\n",
    "                      'max_depth': [4, 5, 6],\n",
    "                      'n_estimators': [32, 128]}\n",
    "\n",
    "  #clf3 = GridSearchCV(xgb.XGBClassifier(random_state=1),\n",
    "  #                  tuned_parameters,\n",
    "  #                  n_jobs=6,\n",
    "  #                  scoring='precision_weighted', \n",
    "  #                  cv=5)\n",
    "  clf3 = create_gridsearch(xgb.XGBClassifier(random_state=1),\n",
    "                      tuned_parameters)\n",
    "  \n",
    "  clf3.fit(x, y)\n",
    "  bs,bp = clf3.best_score_, clf3.best_params_\n",
    "  \n",
    "  return bs, bp, clf3\n",
    "\n",
    "def run_with_mpl(x, y):\n",
    "  tuned_parameters = {'hidden_layer_sizes': [(32,), (64,)],\n",
    "                    'activation': ['tanh', 'relu'],\n",
    "                    'solver': ['lbfgs', 'adam']}\n",
    "  #clf4 = GridSearchCV(MLPClassifier(random_state=1, batch_size=4, early_stopping=True), \n",
    "  #                    tuned_parameters,\n",
    "  #                    n_jobs=6,\n",
    "  #                    scoring='precision_weighted',\n",
    "  #                    cv=5)\n",
    "  clf4 = create_gridsearch(MLPClassifier(random_state=1, batch_size=4, early_stopping=True), \n",
    "                      tuned_parameters)\n",
    "  \n",
    "  clf4.fit(x, y)\n",
    "  bs,bp = clf4.best_score_, clf4.best_params_\n",
    "  \n",
    "  #print('Best score, and parameters, found on development set:')\n",
    "  #print()\n",
    "  #print('%0.3f for %r' % (bs, bp))\n",
    "  #print()\n",
    "  return bs, bp, clf4\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def run_ml_algorithms(features, labels):\n",
    "  mps, _ , clf2= run_with_mpl(features, labels)#\n",
    "  rbs, _, clf1 = run_with_random_forest(features, labels)\n",
    "  xbs,_, clf3 = run_with_XGBClassifer(features, labels)\n",
    "\n",
    "  return [('MPL', clf2,mps), ('RF', clf1, rbs), ('XGB', clf3, xbs)]\n",
    "  #print('Random Forest:{}, MPLClassifier:{} , XGB:{}'.format(rbs, mps, xbs))\n",
    "  #return [('RandomForest',rbs, clf1), ('MPL CLASSIFIER', mps, clf2), ('XGBClassifier',xbs, clf3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now Testing few algorithms FOR TECHNICAL INDICATORS </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    !gsutil cp gs://mm_dataflow_bucket/inputs/tech_cyclical.csv . data\n",
    "    dataset = pd.read_csv('data/tech_cyclical.csv')\\\n",
    "               .dropna().drop('Date', axis=1).drop('ticker', axis=1)\n",
    "    print('Columns are:{}'.format(dataset.columns))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://mm_dataflow_bucket/inputs/tech_cyclical.csv...\n",
      "Omitting directory \"file://.\". (Did you mean to do cp -r?)                      \n",
      "\n",
      "Operation completed over 1 objects/124.7 MiB.                                    \n",
      "Columns are:Index(['high', 'low', 'open', 'close', 'volume', 'adj_close', 'SMA_10',\n",
      "       'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'ema_10', 'ema_20', 'ema_50',\n",
      "       'ema_100', 'ema_200', 'ATR', 'ADX', 'CCI', 'ROC', 'rsi', 'Williams % R',\n",
      "       'SO%K', 'result'],\n",
      "      dtype='object')\n",
      "True:(34595, 25)\n",
      "False:(248415, 25)\n"
     ]
    }
   ],
   "source": [
    "tech_indic = get_dataset()# Too big. We need to bring it to  10k - 20k samples if we want to use this\n",
    "tech_indic.columns\n",
    "tech_indic['increase_15'] = tech_indic['result'] > 1.15\n",
    "print('True:{}'.format(tech_indic[tech_indic['increase_15'] == True].shape))\n",
    "print('False:{}'.format(tech_indic[tech_indic['increase_15'] == False].shape))\n",
    "tech_indic = tech_indic.drop('result', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, y_train, X_test, y_test, test_split = create_train_and_test_split(tech_indic, 'increase_15')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_indic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_algorithms(X, y):\n",
    "    algo_list = run_ml_algorithms(X, y)\n",
    "    for nm, clf,scr in algo_list:\n",
    "        print('{} scored:{}'.format(nm, scr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training on tech indic </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_algorithms(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Running on Test </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Creatin gTensor flow </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['high', 'low', 'open', 'close', 'volume', 'adj_close', 'SMA_10',\n",
       "       'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'ema_10', 'ema_20', 'ema_50',\n",
       "       'ema_100', 'ema_200', 'ATR', 'ADX', 'CCI', 'ROC', 'rsi', 'Williams',\n",
       "       'SOK', 'increase_15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_indic = tech_indic.rename({'Williams % R':'Williams','SO%K':'SOK' }, axis=1)\n",
    "tech_indic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating Train Validation and Split </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181126 train examples\n",
      "45282 validation examples\n",
      "56602 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(tech_indic, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, label, shuffle=True, batch_size=32):\n",
    "  print('Crating dataset for label :{}'.format(label))\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop(label)\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crating dataset for label :increase_15\n",
      "Crating dataset for label :increase_15\n",
      "Crating dataset for label :increase_15\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train, 'increase_15', batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, 'increase_15',shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, 'increase_15',shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Create a Feature Layer </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feture layer for increase_15\n"
     ]
    }
   ],
   "source": [
    "def create_feature_layer(label_col,dataframe):\n",
    "    print('Creating feture layer for {}'.format(label_col))\n",
    "    valid_feats = [c for c in  dataframe.columns.values.tolist() if label_col not in c] \n",
    "    feature_columns = []\n",
    "    for f in valid_feats:\n",
    "        feature_columns.append(feature_column.numeric_column(f))\n",
    "    return  tf.keras.layers.DenseFeatures(feature_columns)\n",
    "feature_layer = create_feature_layer('increase_15', tech_indic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crating dataset for label :increase_15\n",
      "Crating dataset for label :increase_15\n",
      "Crating dataset for label :increase_15\n",
      "Train for 5661 steps, validate for 1416 steps\n",
      "Epoch 1/20\n",
      "5661/5661 [==============================] - 76s 13ms/step - loss: 2737.6502 - accuracy: 0.7830 - val_loss: 452.6659 - val_accuracy: 0.2876\n",
      "Epoch 2/20\n",
      "5661/5661 [==============================] - 81s 14ms/step - loss: 61.7481 - accuracy: 0.8322 - val_loss: 0.7556 - val_accuracy: 0.8784\n",
      "Epoch 3/20\n",
      "5661/5661 [==============================] - 82s 14ms/step - loss: 0.7528 - accuracy: 0.8758 - val_loss: 0.3868 - val_accuracy: 0.8787\n",
      "Epoch 4/20\n",
      "5661/5661 [==============================] - 74s 13ms/step - loss: 0.3790 - accuracy: 0.8774 - val_loss: 0.3713 - val_accuracy: 0.8787\n",
      "Epoch 5/20\n",
      "5661/5661 [==============================] - 69s 12ms/step - loss: 0.3725 - accuracy: 0.8775 - val_loss: 0.3698 - val_accuracy: 0.8787\n",
      "Epoch 6/20\n",
      "5661/5661 [==============================] - 75s 13ms/step - loss: 0.4181 - accuracy: 0.8774 - val_loss: 0.3696 - val_accuracy: 0.8787\n",
      "Epoch 7/20\n",
      "5661/5661 [==============================] - 67s 12ms/step - loss: 0.3766 - accuracy: 0.8775 - val_loss: 0.3695 - val_accuracy: 0.8787\n",
      "Epoch 8/20\n",
      "5661/5661 [==============================] - 72s 13ms/step - loss: 0.3724 - accuracy: 0.8775 - val_loss: 0.3696 - val_accuracy: 0.8787\n",
      "Epoch 9/20\n",
      "5661/5661 [==============================] - 75s 13ms/step - loss: 0.3721 - accuracy: 0.8776 - val_loss: 0.3694 - val_accuracy: 0.8787\n",
      "Epoch 10/20\n",
      "5661/5661 [==============================] - 61s 11ms/step - loss: 0.3721 - accuracy: 0.8775 - val_loss: 0.3697 - val_accuracy: 0.8787\n",
      "Epoch 11/20\n",
      "5661/5661 [==============================] - 67s 12ms/step - loss: 0.3838 - accuracy: 0.8776 - val_loss: 0.3698 - val_accuracy: 0.8787\n",
      "Epoch 12/20\n",
      "5661/5661 [==============================] - 69s 12ms/step - loss: 2.0194 - accuracy: 0.8749 - val_loss: 0.3698 - val_accuracy: 0.8786\n",
      "Epoch 13/20\n",
      "5661/5661 [==============================] - 64s 11ms/step - loss: 0.7773 - accuracy: 0.8775 - val_loss: 0.3696 - val_accuracy: 0.8787\n",
      "Epoch 14/20\n",
      "5661/5661 [==============================] - 72s 13ms/step - loss: 0.4269 - accuracy: 0.8774 - val_loss: 0.3699 - val_accuracy: 0.8787\n",
      "Epoch 15/20\n",
      "5661/5661 [==============================] - 63s 11ms/step - loss: 0.3743 - accuracy: 0.8775 - val_loss: 0.3694 - val_accuracy: 0.8787\n",
      "Epoch 16/20\n",
      "5661/5661 [==============================] - 70s 12ms/step - loss: 0.3719 - accuracy: 0.8776 - val_loss: 0.3695 - val_accuracy: 0.8787\n",
      "Epoch 17/20\n",
      "5661/5661 [==============================] - 74s 13ms/step - loss: 0.3720 - accuracy: 0.8775 - val_loss: 0.3693 - val_accuracy: 0.8787\n",
      "Epoch 18/20\n",
      "5661/5661 [==============================] - 72s 13ms/step - loss: 0.5884 - accuracy: 0.8775 - val_loss: 0.3693 - val_accuracy: 0.8787\n",
      "Epoch 19/20\n",
      "5661/5661 [==============================] - 63s 11ms/step - loss: 0.3719 - accuracy: 0.8776 - val_loss: 0.3693 - val_accuracy: 0.8787\n",
      "Epoch 20/20\n",
      "5661/5661 [==============================] - 60s 11ms/step - loss: 0.3719 - accuracy: 0.8776 - val_loss: 0.3693 - val_accuracy: 0.8787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff0a1463410>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train,'increase_15', batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, 'increase_15',shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test,'increase_15', shuffle=False, batch_size=batch_size)\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluating</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1769/1769 [==============================] - 11s 6ms/step - loss: 0.3897 - accuracy: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3896771559629688, 0.87783116]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Predict </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Load the Data into dataframe\n",
    "\n",
    "#2 Call DF to Dataset\n",
    "\n",
    "#3 Call model.predict\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "model.predict(x_test[:3])\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Reading Quartely Reports </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!gsutil cp gs://mm_dataflow_bucket/inputs/top10_corr_df_1008.pkl  .\n",
    "!gsutil cp gs://mm_dataflow_bucket/inputs/top10_df_classifier_1008.pkl .\n",
    "\n",
    "df = pd.read_pickle('top10_corr_df_1008.pkl')\n",
    "df = df.fillna(0.0)\n",
    "print('Shape is:{}'.format(df.shape))\n",
    "print('Columns are:{}'.format(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Running Technical indicators Algs </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, test_split = create_train_and_test_split(df, 'Decision')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Performance on Training. We need to sort out data. we only get 50% performance. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ml_algorithms(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Performance on test </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ml_algorithms(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Not reliable as it's to accurate. Let's attempt for example to predict if price is > 5%. Also we can try to widen the dataset by searching all shares </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evlauatin gPerformance </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_df = pd.read_csv('data/prices.csv')\n",
    "prices_df = prices_df.rename(columns={\"Unnamed: 0\": \"ticker\"})\n",
    "tickers = prices_df['ticker'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clsfier_tpl, x_t, y_t):\n",
    "    nm, clsf, t_score = clsfier_tpl\n",
    "    y_pred = clsf.predict(x_t)\n",
    "    a_s = accuracy_score(y_t, y_pred)\n",
    "    print('{} has accuracy {} on test and {} on train'.format(nm, a_s, t_score) )\n",
    "    print('--------------------------')\n",
    "    print(print(classification_report(y_t, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clsf_tpl in algo_list:\n",
    "    evaluate(clsf_tpl,X_test, y_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> TODO. Pass current technical indicator for a share and see what is the prediction ... </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Checking how good classifier are on real prediction </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar_test = prices_df.loc[test_split.index.values, :]\n",
    "buy_amount = 100\n",
    "\n",
    "clf2, clf3, clf4 = algo_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial investment can be $100 for each stock whose predicted class = 1\n",
    "buy_amount = 100\n",
    "# In new dataframe df1, store all the information regarding each model's predicted class and relative gain/loss in $USD\n",
    "df1 = pd.DataFrame(y_test, index=test_split.index.values, columns=['ACTUAL']) # first column is the true class (BUY/INGORE)\n",
    "df1['RF'] = clf2[1].predict(X_test)\n",
    "df1['VALUE START RF [$]'] = df1['RF'] * buy_amount\n",
    "df1['VAR RF [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START RF [$]']\n",
    "df1['VALUE END RF [$]'] = df1['VALUE START RF [$]'] + df1['VAR RF [$]']\n",
    "df1['XGB'] = clf4[1].predict(X_test)\n",
    "df1['VALUE START XGB [$]'] = df1['XGB'] * buy_amount\n",
    "df1['VAR XGB [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START XGB [$]']\n",
    "df1['VALUE END XGB [$]'] = df1['VALUE START XGB [$]'] + df1['VAR XGB [$]']\n",
    "df1['MLP'] = clf3[1].predict(X_test)\n",
    "df1['VALUE START MLP [$]'] = df1['MLP'] * buy_amount\n",
    "df1['VAR MLP [$]'] = (pvar_test['2019 PRICE VAR [%]'].values / 100) * df1['VALUE START MLP [$]']\n",
    "df1['VALUE END MLP [$]'] = df1['VALUE START MLP [$]'] + df1['VAR MLP [$]']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evaluate Performance </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_value_rf = df1['VALUE START RF [$]'].sum()\n",
    "final_value_rf = df1['VALUE END RF [$]'].sum()\n",
    "net_gain_rf = final_value_rf - start_value_rf\n",
    "percent_gain_rf = (net_gain_rf / start_value_rf) * 100\n",
    "start_value_xgb = df1['VALUE START XGB [$]'].sum()\n",
    "final_value_xgb = df1['VALUE END XGB [$]'].sum()\n",
    "net_gain_xgb = final_value_xgb - start_value_xgb\n",
    "percent_gain_xgb = (net_gain_xgb / start_value_xgb) * 100\n",
    "start_value_mlp = df1['VALUE START MLP [$]'].sum()\n",
    "final_value_mlp = df1['VALUE END MLP [$]'].sum()\n",
    "net_gain_mlp = final_value_mlp - start_value_mlp\n",
    "percent_gain_mlp = (net_gain_mlp / start_value_mlp) * 100\n",
    "percent_gain_sp500 = get_price_var('^GSPC') # get percent gain of S&P500 index\n",
    "percent_gain_dj = get_price_var('^DJI') # get percent gain of DOW JONES index\n",
    "\n",
    "\n",
    "MODELS_COMPARISON = pd.DataFrame([start_value_rf, final_value_rf, net_gain_rf, percent_gain_rf],\n",
    "                    index=['INITIAL COST [USD]', 'FINAL VALUE [USD]', '[USD] GAIN/LOSS', 'ROI'], columns=['RF'])\n",
    "\n",
    "MODELS_COMPARISON['XGB'] = [start_value_xgb, final_value_xgb, net_gain_xgb, percent_gain_xgb]\n",
    "MODELS_COMPARISON['MLP'] = [start_value_mlp, final_value_mlp, net_gain_mlp, percent_gain_mlp]\n",
    "MODELS_COMPARISON['S&P 500'] = ['', '', '', percent_gain_sp500]\n",
    "MODELS_COMPARISON['DOW JONES'] = ['', '', '', percent_gain_dj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
